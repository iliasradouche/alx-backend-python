#!/bin/bash

# kubctl-0x03: Rolling Update Management Script
# This script performs rolling updates with zero-downtime monitoring
# Author: ALX Backend Python Course
# Version: 1.0

set -euo pipefail  # Exit on error, undefined vars, pipe failures

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
NAMESPACE="default"
DEPLOYMENT="django-messaging-app-blue"
SERVICE="django-messaging-service"
DEPLOYMENT_FILE="blue_deployment.yaml"
TIMEOUT=600  # 10 minutes timeout
TEST_INTERVAL=2  # Test every 2 seconds
MAX_DOWNTIME_TESTS=300  # Maximum number of downtime tests (10 minutes)

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_test() {
    echo -e "${CYAN}[TEST]${NC} $1"
}

# Function to check prerequisites
check_prerequisites() {
    print_status "Checking prerequisites..."
    
    # Check if kubectl is installed
    if ! command -v kubectl &> /dev/null; then
        print_error "kubectl is not installed or not in PATH"
        exit 1
    fi
    
    # Check if curl is installed
    if ! command -v curl &> /dev/null; then
        print_error "curl is not installed or not in PATH"
        exit 1
    fi
    
    # Check if cluster is accessible
    if ! kubectl cluster-info &> /dev/null; then
        print_error "Cannot connect to Kubernetes cluster"
        exit 1
    fi
    
    # Check if deployment file exists
    if [[ ! -f "$DEPLOYMENT_FILE" ]]; then
        print_error "Deployment file $DEPLOYMENT_FILE not found"
        exit 1
    fi
    
    # Check if deployment exists
    if ! kubectl get deployment $DEPLOYMENT -n $NAMESPACE &> /dev/null; then
        print_error "Deployment $DEPLOYMENT not found in namespace $NAMESPACE"
        exit 1
    fi
    
    print_success "Prerequisites check passed"
}

# Function to get service URL for testing
get_service_url() {
    local service_type=$(kubectl get service $SERVICE -n $NAMESPACE -o jsonpath='{.spec.type}' 2>/dev/null || echo "")
    
    if [[ "$service_type" == "NodePort" ]]; then
        local node_port=$(kubectl get service $SERVICE -n $NAMESPACE -o jsonpath='{.spec.ports[0].nodePort}')
        local minikube_ip=$(minikube ip 2>/dev/null || echo "localhost")
        echo "http://$minikube_ip:$node_port"
    elif [[ "$service_type" == "LoadBalancer" ]]; then
        local external_ip=$(kubectl get service $SERVICE -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
        if [[ -n "$external_ip" ]]; then
            echo "http://$external_ip"
        else
            # Fallback to port-forward
            echo "port-forward"
        fi
    else
        # ClusterIP - use port-forward
        echo "port-forward"
    fi
}

# Function to start port-forward if needed
start_port_forward() {
    local service_url="$1"
    
    if [[ "$service_url" == "port-forward" ]]; then
        print_status "Starting port-forward for service $SERVICE..."
        kubectl port-forward service/$SERVICE 8080:80 -n $NAMESPACE &
        local port_forward_pid=$!
        sleep 3  # Give port-forward time to start
        echo "http://localhost:8080"
        return $port_forward_pid
    else
        echo "$service_url"
        return 0
    fi
}

# Function to stop port-forward
stop_port_forward() {
    local pid=$1
    if [[ $pid -gt 0 ]]; then
        kill $pid 2>/dev/null || true
        print_status "Port-forward stopped"
    fi
}

# Function to test application availability
test_application() {
    local url="$1"
    local timeout=5
    
    # Test the main endpoint
    if curl -s --max-time $timeout "$url/" > /dev/null 2>&1; then
        return 0
    elif curl -s --max-time $timeout "$url/admin/" > /dev/null 2>&1; then
        return 0
    else
        return 1
    fi
}

# Function to monitor downtime during rolling update
monitor_downtime() {
    local service_url="$1"
    local port_forward_pid="$2"
    
    print_status "Starting downtime monitoring..."
    print_test "Testing URL: $service_url"
    
    local downtime_count=0
    local total_tests=0
    local consecutive_failures=0
    local max_consecutive_failures=0
    local start_time=$(date +%s)
    
    # Create log file for detailed results
    local log_file="downtime_test_$(date +%Y%m%d_%H%M%S).log"
    echo "Rolling Update Downtime Test - $(date)" > "$log_file"
    echo "Service URL: $service_url" >> "$log_file"
    echo "Test Interval: ${TEST_INTERVAL}s" >> "$log_file"
    echo "----------------------------------------" >> "$log_file"
    
    print_status "Downtime monitoring started. Press Ctrl+C to stop."
    
    # Trap to handle cleanup on exit
    trap 'stop_port_forward $port_forward_pid; print_status "Downtime monitoring stopped"; exit 0' INT TERM
    
    while [[ $total_tests -lt $MAX_DOWNTIME_TESTS ]]; do
        local test_start=$(date +%s.%N)
        
        if test_application "$service_url"; then
            local test_end=$(date +%s.%N)
            local response_time=$(echo "$test_end - $test_start" | bc -l 2>/dev/null || echo "N/A")
            
            printf "\r${GREEN}✓${NC} Test %d: OK (%.3fs)" $((total_tests + 1)) "$response_time"
            echo "$(date '+%H:%M:%S') - Test $((total_tests + 1)): SUCCESS (${response_time}s)" >> "$log_file"
            
            if [[ $consecutive_failures -gt 0 ]]; then
                echo "" # New line after failures
                print_success "Service recovered after $consecutive_failures consecutive failures"
                echo "$(date '+%H:%M:%S') - Service recovered after $consecutive_failures failures" >> "$log_file"
            fi
            consecutive_failures=0
        else
            local test_end=$(date +%s.%N)
            local response_time=$(echo "$test_end - $test_start" | bc -l 2>/dev/null || echo "N/A")
            
            printf "\r${RED}✗${NC} Test %d: FAILED (%.3fs)" $((total_tests + 1)) "$response_time"
            echo "$(date '+%H:%M:%S') - Test $((total_tests + 1)): FAILED (${response_time}s)" >> "$log_file"
            
            downtime_count=$((downtime_count + 1))
            consecutive_failures=$((consecutive_failures + 1))
            
            if [[ $consecutive_failures -gt $max_consecutive_failures ]]; then
                max_consecutive_failures=$consecutive_failures
            fi
            
            if [[ $consecutive_failures -eq 1 ]]; then
                echo "" # New line before first failure
                print_warning "Downtime detected!"
            fi
        fi
        
        total_tests=$((total_tests + 1))
        sleep $TEST_INTERVAL
    done
    
    # Final statistics
    local end_time=$(date +%s)
    local total_duration=$((end_time - start_time))
    local downtime_percentage=$(echo "scale=2; $downtime_count * 100 / $total_tests" | bc -l 2>/dev/null || echo "0")
    
    echo ""
    echo "----------------------------------------" >> "$log_file"
    echo "Final Statistics:" >> "$log_file"
    echo "Total Tests: $total_tests" >> "$log_file"
    echo "Failed Tests: $downtime_count" >> "$log_file"
    echo "Success Rate: $(echo "scale=2; ($total_tests - $downtime_count) * 100 / $total_tests" | bc -l)%" >> "$log_file"
    echo "Downtime Percentage: ${downtime_percentage}%" >> "$log_file"
    echo "Max Consecutive Failures: $max_consecutive_failures" >> "$log_file"
    echo "Total Duration: ${total_duration}s" >> "$log_file"
    
    print_status "Downtime monitoring completed"
    print_status "Total tests: $total_tests"
    print_status "Failed tests: $downtime_count"
    print_status "Downtime percentage: ${downtime_percentage}%"
    print_status "Max consecutive failures: $max_consecutive_failures"
    print_status "Detailed log saved to: $log_file"
    
    stop_port_forward "$port_forward_pid"
}

# Function to apply rolling update
apply_rolling_update() {
    print_status "Applying rolling update..."
    
    # Apply the updated deployment
    if kubectl apply -f "$DEPLOYMENT_FILE"; then
        print_success "Deployment configuration applied"
    else
        print_error "Failed to apply deployment configuration"
        return 1
    fi
    
    # Trigger rolling update by adding annotation
    local timestamp=$(date +%s)
    if kubectl annotate deployment $DEPLOYMENT -n $NAMESPACE deployment.kubernetes.io/revision="$timestamp" --overwrite; then
        print_success "Rolling update triggered"
    else
        print_warning "Failed to add annotation, but deployment may still update"
    fi
}

# Function to monitor rollout status
monitor_rollout() {
    print_status "Monitoring rollout status..."
    
    # Start rollout status monitoring in background
    kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE --timeout=${TIMEOUT}s &
    local rollout_pid=$!
    
    # Wait for rollout to complete
    if wait $rollout_pid; then
        print_success "Rolling update completed successfully"
        return 0
    else
        print_error "Rolling update failed or timed out"
        return 1
    fi
}

# Function to verify rolling update completion
verify_rollout() {
    print_status "Verifying rolling update completion..."
    
    # Check deployment status
    local ready_replicas=$(kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
    local desired_replicas=$(kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
    
    if [[ "$ready_replicas" == "$desired_replicas" ]] && [[ "$ready_replicas" -gt 0 ]]; then
        print_success "All replicas are ready ($ready_replicas/$desired_replicas)"
    else
        print_error "Not all replicas are ready ($ready_replicas/$desired_replicas)"
        return 1
    fi
    
    # Check pod status
    print_status "Current pod status:"
    kubectl get pods -l app=$DEPLOYMENT -n $NAMESPACE -o wide
    
    # Verify image version
    print_status "Verifying image versions:"
    kubectl describe deployment $DEPLOYMENT -n $NAMESPACE | grep Image: || true
    
    # Check rollout history
    print_status "Rollout history:"
    kubectl rollout history deployment/$DEPLOYMENT -n $NAMESPACE
    
    return 0
}

# Function to show help
show_help() {
    cat << EOF
kubctl-0x03: Rolling Update Management Script

USAGE:
    ./kubctl-0x03 [COMMAND] [OPTIONS]

COMMANDS:
    rolling-update  Perform complete rolling update with monitoring
    apply-only      Apply deployment changes only
    monitor-only    Monitor existing rollout
    verify-only     Verify rollout completion
    downtime-test   Test for downtime only (no deployment changes)
    help            Show this help message

OPTIONS:
    --namespace     Kubernetes namespace (default: default)
    --timeout       Timeout in seconds (default: 600)
    --deployment    Deployment name (default: django-messaging-app-blue)
    --file          Deployment file (default: blue_deployment.yaml)

EXAMPLES:
    ./kubctl-0x03 rolling-update
    ./kubctl-0x03 apply-only
    ./kubctl-0x03 monitor-only
    ./kubctl-0x03 downtime-test
    ./kubctl-0x03 verify-only

EOF
}

# Main function for complete rolling update
perform_rolling_update() {
    print_status "Starting complete rolling update process..."
    
    # Step 1: Check prerequisites
    check_prerequisites
    
    # Step 2: Get service URL for testing
    local service_url=$(get_service_url)
    local port_forward_pid=0
    
    service_url=$(start_port_forward "$service_url")
    if [[ $? -gt 0 ]]; then
        port_forward_pid=$?
    fi
    
    print_status "Service URL for testing: $service_url"
    
    # Step 3: Test initial connectivity
    print_test "Testing initial connectivity..."
    if test_application "$service_url"; then
        print_success "Initial connectivity test passed"
    else
        print_error "Initial connectivity test failed"
        stop_port_forward "$port_forward_pid"
        exit 1
    fi
    
    # Step 4: Start downtime monitoring in background
    monitor_downtime "$service_url" "$port_forward_pid" &
    local monitor_pid=$!
    
    # Give monitoring time to start
    sleep 3
    
    # Step 5: Apply rolling update
    if ! apply_rolling_update; then
        print_error "Failed to apply rolling update"
        kill $monitor_pid 2>/dev/null || true
        stop_port_forward "$port_forward_pid"
        exit 1
    fi
    
    # Step 6: Monitor rollout status
    if ! monitor_rollout; then
        print_error "Rolling update failed"
        kill $monitor_pid 2>/dev/null || true
        stop_port_forward "$port_forward_pid"
        exit 1
    fi
    
    # Step 7: Verify completion
    if ! verify_rollout; then
        print_error "Rolling update verification failed"
        kill $monitor_pid 2>/dev/null || true
        stop_port_forward "$port_forward_pid"
        exit 1
    fi
    
    # Step 8: Stop monitoring and cleanup
    print_status "Stopping downtime monitoring..."
    kill $monitor_pid 2>/dev/null || true
    wait $monitor_pid 2>/dev/null || true
    
    print_success "Rolling update completed successfully!"
    print_status "Final application test..."
    
    if test_application "$service_url"; then
        print_success "Final connectivity test passed"
    else
        print_warning "Final connectivity test failed"
    fi
    
    stop_port_forward "$port_forward_pid"
}

# Parse command line arguments
case "${1:-rolling-update}" in
    "rolling-update")
        perform_rolling_update
        ;;
    "apply-only")
        check_prerequisites
        apply_rolling_update
        ;;
    "monitor-only")
        check_prerequisites
        monitor_rollout
        ;;
    "verify-only")
        check_prerequisites
        verify_rollout
        ;;
    "downtime-test")
        check_prerequisites
        service_url=$(get_service_url)
        port_forward_pid=0
        service_url=$(start_port_forward "$service_url")
        if [[ $? -gt 0 ]]; then
            port_forward_pid=$?
        fi
        monitor_downtime "$service_url" "$port_forward_pid"
        ;;
    "help"|"--help"|"-h")
        show_help
        ;;
    *)
        print_error "Unknown command: $1"
        show_help
        exit 1
        ;;
esac